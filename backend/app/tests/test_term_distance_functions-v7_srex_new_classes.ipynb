{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing GraphSearch Distance Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from models.srex.ranking import Ranking\n",
    "from utils.data_utils import DataUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Stop Words\n",
    "stop_words_list = DataUtils.load_stopwords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query                    = '\"internet of things\" OR iot'\n",
    "#query                    = 'a!\"#$\"#\"$\"'\n",
    "query                     = 'query AND (expansion OR refinement)'\n",
    "#query                    = '(\"Document Title\":internet of things   OR   (\"Document Title\":iot  AND \"Document Title\":device  )  )  AND (\"Abstract\":security NOT  \"Abstract\":visual OR \"Document Title\":network)'\n",
    "#query                    = '((( literature  OR document OR information OR data ) AND (retrieval OR retrieve)) OR (search AND engine)  )  AND  (query AND  ( expansion OR refinement OR reformulation))'\n",
    "nr_search_results        = 10\n",
    "\n",
    "ranking_weight_type      = 'linear' # it can be: 'none', 'linear' or 'inverse'\n",
    "lema                     = True\n",
    "stem                     = False\n",
    "summarize                = 'mean'   # it can be: 'mean' or 'median'\n",
    "nr_of_graph_terms        = 10\n",
    "limit_distance           = 4 \n",
    "include_query_terms  = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while processing article at index 0: Abstract and title cannot be both empty\n"
     ]
    }
   ],
   "source": [
    "ranking = Ranking(query, nr_search_results, ranking_weight_type, stop_words_list, lema, stem)\n",
    "ranking.calculate_ieee_xplore_ranking()\n",
    "#ranking.calculate_article_dictionaries_list([{}])\n",
    "#articles = ranking.get_ieee_xplore_ranking()\n",
    "#dicts = [{\"title\": a.get('title', ''), \"abstract\": a.get('abstract', ''), \"article_number\": a.get('article_number', '')} for a in articles]\n",
    "#import json\n",
    "#print(json.dumps(dicts, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No documents were found\n"
     ]
    }
   ],
   "source": [
    "ranking.generate_all_graphs(nr_of_graph_terms, limit_distance, include_query_terms, summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: A survey of query expansion, query suggestion and query refinement techniques (id:7333094)\n",
      "txt: survey query expansion query suggestion query refinement technique\n",
      "txt: ineffectiveness information retrieval system often caused inaccurate use keywords query\n",
      "txt: \n",
      "txt: common technique revolving around query modification technique query expansion query refinement\n",
      "txt: due high similarity query modification technique people often confused difference\n",
      "txt: \n",
      "txt: hence paper first briefly discus basic technique query expansion query suggestion query refinement make detailed comparison three technique\n",
      "txt: finally show promising future research trend field query modification\n",
      "TITLE: Disjunctive Sets of Phrase Queries for Diverse Query Suggestion (id:8909632)\n",
      "txt: disjunctive set phrase query diverse query suggestion\n",
      "txt: paper proposes method suggesting expanded query disambiguate original web query multiple interpretation\n",
      "txt: order produce diverse set query including corresponding infrequent query intent method produce query extracting phrase connecting given query term corpus\n",
      "txt: use corpus infrequent query intent may appear query log\n",
      "txt: use phrase query need sufficiently specific query retrieving page corresponding infrequent query intent many page corresponding popular query intent\n",
      "txt: phrase query usually high accuracy low recall\n",
      "txt: order also achieve high recall use disjunction many phrase query query\n",
      "txt: method first produce many phrase query term expansion phrase extraction corpus group semantically similar phrase cluster use cluster disjunctive set phrase query\n",
      "TITLE: Probabilistic Query Expansion method using recommended past user queries (id:6457806)\n",
      "txt: probabilistic query expansion method recommended past user query\n",
      "txt: plenty query expansion technique proposed solve problem information retrieval system new challenge introduced method expansion user query rapid growth size web collection\n",
      "txt: paper focused attention improvement precision user query probabilistic query expansion method\n",
      "txt: approach consists use information contained query log includes past user query clicked document providing recommendation\n",
      "txt: experiment result show precision short query increase even add term number term added affect long query precision much short query\n",
      "TITLE: Acquiring Lexical Knowledge from Query Logs for Query Expansion in Patent Searching (id:6337124)\n",
      "txt: acquiring lexical knowledge query log query expansion patent searching\n",
      "txt: query expansion crucial step domain patent searching\n",
      "txt: currently automatic query expansion patent search mostly based statistical measure\n",
      "txt: additional query term extracted query document based entropy measure\n",
      "txt: automate query expansion patent searching acquire lexical knowledge query log uspto patent examiner\n",
      "txt: result show good performance query expansion patent searching lexical database\n",
      "txt: help improving automated query expansion patent searching\n",
      "TITLE: Enhancing Video Retrieval: A User Behavior-Based Query Expansion Approach (id:10456494)\n",
      "txt: enhancing video retrieval user query expansion approach\n",
      "txt: study propose user query optimization strategy address commonly observed suboptimal query performance user experience field video retrieval\n",
      "txt: strategy primarily involves analyzing user behavioral data video retrieval process expand query keywords enhancing relevance diversity thus optimizing search result\n",
      "txt: \n",
      "txt: subsequently automated query expansion algorithm effectively applied data video retrieval\n",
      "txt: \n",
      "txt: result demonstrate user driven query expansion approach significantly improves accuracy video retrieval user satisfaction\n",
      "TITLE: A search log sparseness oriented query expansion method (id:7009440)\n",
      "txt: search log sparseness oriented query expansion method\n",
      "txt: query expansion method based search log improve quality search result extends\n",
      "txt: search log sparse kind query expansion method poor quality search result unable meet user search request\n",
      "txt: paper present search log sparseness oriented query extension method\n",
      "txt: introducing determination rule data sparseness method selects expansion term high performance expansion term given local context based method go disadvantage search log based method sparse data set providing expansion term higher quality user initial query\n",
      "txt: \n",
      "TITLE: Combining Query Reformulation and Re-ranking to Improve Query Expansion in Chinese EMR Retrieval (id:9669713)\n",
      "txt: combining query reformulation improve query expansion chinese emr retrieval\n",
      "txt: method query expansion qe achieved significant performance information retrieval electronic medical record emr\n",
      "txt: pity direct addition expansion term may cause query drift decrease precision emr retrieval\n",
      "txt: solve issue combine method query reformulation improve performance qe chinese emr retrieval\n",
      "txt: first synonym hyponym extracted chinese medical knowledge graph expansion term weight expansion term calculated combination semantic similarity category weight frequency\n",
      "txt: query reformulated expansion term emr document retrieved expanded query\n",
      "txt: \n",
      "txt: \n",
      "txt: experiment show algorithm promote effectiveness emr retrieval compared baseline show combination query reformulation differentiate expansion term different category maximize effect\n",
      "TITLE: An ontological approach for SQL query expansion (id:6216617)\n",
      "txt: ontological approach sql query expansion\n",
      "txt: \n",
      "txt: \n",
      "txt: \n",
      "txt: first aim help user search initial query return result\n",
      "txt: propose ontological approach sql query expansion based different refinement type\n",
      "txt: \n",
      "TITLE: Ontology-Driven Query Expansion Using Map/Reduce Framework to Facilitate Federated Queries (id:6009465)\n",
      "txt: query expansion framework facilitate federated query\n",
      "txt: view need highly distributed federated architecture robust query expansion great impact performance information retrieval\n",
      "txt: aim determine query expansion term different weighting technique\n",
      "txt: consider individual ontology user query keywords determine basic expansion term bet number semantic measure including betweenness measure bm semantic similarity measure ssm\n",
      "txt: \n",
      "txt: \n",
      "TITLE: Learning query expansion from association rules between terms (id:7526965)\n",
      "txt: learning query expansion association rule term\n",
      "txt: query expansion technique offer interesting solution obtaining complete answer user query preserving quality retained document\n",
      "txt: mainly relies accurate choice added term initial query\n",
      "txt: \n",
      "txt: face huge number derived association rule order select optimal combination query term generic basis propose model problem classification problem solve supervised learning algorithm\n",
      "txt: purpose first generate training set genetic algorithm based approach explores association rule space order find optimal set expansion term improving map search result build model able predict association rule used expanding query\n",
      "txt: \n",
      "txt: main observation hybridization textmining technique query expansion intelligent way allows u incorporate good feature\n",
      "txt: \n"
     ]
    }
   ],
   "source": [
    "for d in ranking.get_documents():\n",
    "    print(f\"TITLE: {d.get_title()} (id:{d.get_doc_id()})\")\n",
    "    for s in d.get_sentences():\n",
    "        print(f\"txt: {s.get_preprocessed_text()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc: A survey of query expansion, query suggestion and query refinement techniques\n",
      "vecinity matrix: {'survey': {'query': [1, 0, 1, 0], 'expansion': [0, 1, 0, 0]}, 'query': {'expansion': [2, 0, 1, 0], 'refinement': [1, 0, 1, 0]}, 'expansion': {'query': [2, 0, 1, 0], 'refinement': [0, 0, 0, 1]}, 'suggestion': {'query': [2, 0, 1, 0], 'expansion': [0, 1, 0, 0], 'refinement': [0, 1, 0, 0]}, 'refinement': {'query': [1, 0, 1, 0], 'expansion': [0, 0, 0, 1]}, 'technique': {'query': [0, 1, 0, 1], 'refinement': [1, 0, 0, 0]}}\n",
      "vecinity matrix: {'caused': {'query': [0, 0, 0, 1]}, 'inaccurate': {'query': [0, 0, 1, 0]}, 'use': {'query': [0, 1, 0, 0]}, 'keywords': {'query': [1, 0, 0, 0]}}\n",
      "vecinity matrix: {}\n",
      "vecinity matrix: {'common': {'query': [0, 0, 0, 1]}, 'technique': {'query': [1, 1, 2, 0], 'expansion': [0, 1, 0, 0], 'refinement': [0, 0, 0, 1]}, 'revolving': {'query': [0, 1, 0, 0]}, 'around': {'query': [1, 0, 0, 1]}, 'query': {'expansion': [2, 0, 0, 1], 'refinement': [1, 0, 1, 0]}, 'modification': {'query': [1, 1, 0, 1], 'expansion': [0, 0, 1, 0]}, 'expansion': {'query': [2, 0, 0, 1], 'refinement': [0, 1, 0, 0]}, 'refinement': {'query': [1, 0, 1, 0], 'expansion': [0, 1, 0, 0]}}\n",
      "vecinity matrix: {'due': {'query': [0, 0, 1, 0]}, 'high': {'query': [0, 1, 0, 0]}, 'similarity': {'query': [1, 0, 0, 0]}, 'modification': {'query': [1, 0, 0, 0]}, 'technique': {'query': [0, 1, 0, 0]}, 'people': {'query': [0, 0, 1, 0]}, 'often': {'query': [0, 0, 0, 1]}}\n",
      "vecinity matrix: {}\n",
      "vecinity matrix: {'briefly': {'query': [0, 0, 0, 1]}, 'discus': {'query': [0, 0, 1, 0], 'expansion': [0, 0, 0, 1]}, 'basic': {'query': [0, 1, 0, 1], 'expansion': [0, 0, 1, 0]}, 'technique': {'query': [1, 0, 1, 0], 'expansion': [0, 1, 0, 0]}, 'query': {'expansion': [2, 0, 1, 0], 'refinement': [1, 0, 1, 0]}, 'expansion': {'query': [2, 0, 1, 0], 'refinement': [0, 0, 0, 1]}, 'suggestion': {'query': [2, 0, 1, 0], 'expansion': [0, 1, 0, 0], 'refinement': [0, 1, 0, 0]}, 'refinement': {'query': [1, 0, 1, 0], 'expansion': [0, 0, 0, 1]}, 'make': {'query': [0, 1, 0, 1], 'refinement': [1, 0, 0, 0]}, 'detailed': {'query': [0, 0, 1, 0], 'refinement': [0, 1, 0, 0]}, 'comparison': {'query': [0, 0, 0, 1], 'refinement': [0, 0, 1, 0]}, 'three': {'refinement': [0, 0, 0, 1]}}\n",
      "vecinity matrix: {'future': {'query': [0, 0, 0, 1]}, 'research': {'query': [0, 0, 1, 0]}, 'trend': {'query': [0, 1, 0, 0]}, 'field': {'query': [1, 0, 0, 0]}, 'modification': {'query': [1, 0, 0, 0]}}\n",
      "doc: Disjunctive Sets of Phrase Queries for Diverse Query Suggestion\n",
      "vecinity matrix: {'disjunctive': {'query': [0, 0, 1, 0]}, 'set': {'query': [0, 1, 0, 1]}, 'phrase': {'query': [1, 0, 1, 0]}, 'diverse': {'query': [2, 0, 0, 0]}, 'suggestion': {'query': [1, 0, 1, 0]}}\n",
      "vecinity matrix: {'proposes': {'query': [0, 0, 0, 1]}, 'method': {'query': [0, 0, 1, 0]}, 'suggesting': {'query': [0, 1, 0, 0]}, 'expanded': {'query': [1, 0, 0, 0]}, 'disambiguate': {'query': [1, 0, 1, 0]}, 'original': {'query': [0, 2, 0, 0]}, 'web': {'query': [1, 0, 1, 0]}, 'multiple': {'query': [1, 0, 0, 0]}, 'interpretation': {'query': [0, 1, 0, 0]}}\n",
      "vecinity matrix: {'order': {'query': [0, 0, 0, 1]}, 'produce': {'query': [1, 0, 2, 0]}, 'diverse': {'query': [0, 1, 0, 0]}, 'set': {'query': [1, 0, 0, 0]}, 'including': {'query': [1, 0, 1, 0]}, 'corresponding': {'query': [0, 2, 0, 0]}, 'infrequent': {'query': [1, 0, 1, 0]}, 'intent': {'query': [1, 0, 1, 0]}, 'method': {'query': [0, 2, 0, 0]}, 'extracting': {'query': [1, 0, 0, 1]}, 'phrase': {'query': [0, 1, 1, 0]}, 'connecting': {'query': [0, 1, 1, 0]}, 'given': {'query': [1, 0, 0, 1]}, 'term': {'query': [1, 0, 0, 0]}, 'corpus': {'query': [0, 1, 0, 0]}}\n",
      "vecinity matrix: {'use': {'query': [0, 0, 1, 0]}, 'corpus': {'query': [0, 1, 0, 0]}, 'infrequent': {'query': [1, 0, 0, 0]}, 'intent': {'query': [1, 0, 1, 0]}, 'may': {'query': [0, 2, 0, 0]}, 'appear': {'query': [1, 0, 1, 0]}, 'log': {'query': [1, 0, 0, 0]}}\n",
      "vecinity matrix: {'use': {'query': [0, 1, 0, 0]}, 'phrase': {'query': [1, 0, 0, 0]}, 'need': {'query': [1, 0, 1, 0]}, 'sufficiently': {'query': [0, 2, 0, 0]}, 'specific': {'query': [1, 0, 1, 0]}, 'retrieving': {'query': [1, 0, 0, 1]}, 'page': {'query': [0, 1, 3, 0]}, 'corresponding': {'query': [0, 2, 1, 1]}, 'infrequent': {'query': [1, 0, 0, 1]}, 'intent': {'query': [2, 0, 0, 0]}, 'many': {'query': [0, 1, 0, 1]}, 'popular': {'query': [1, 0, 0, 0]}}\n",
      "vecinity matrix: {'phrase': {'query': [1, 0, 0, 0]}, 'usually': {'query': [1, 0, 0, 0]}, 'high': {'query': [0, 1, 0, 0]}, 'accuracy': {'query': [0, 0, 1, 0]}, 'low': {'query': [0, 0, 0, 1]}}\n",
      "vecinity matrix: {'use': {'query': [0, 0, 0, 1]}, 'disjunction': {'query': [0, 0, 1, 1]}, 'many': {'query': [0, 1, 1, 0]}, 'phrase': {'query': [1, 1, 0, 0]}}\n",
      "vecinity matrix: {'first': {'query': [0, 0, 0, 1]}, 'produce': {'query': [0, 0, 1, 0]}, 'many': {'query': [0, 1, 0, 0], 'expansion': [0, 0, 0, 1]}, 'phrase': {'query': [2, 0, 1, 0], 'expansion': [1, 0, 1, 0]}, 'query': {'expansion': [0, 1, 0, 0]}, 'term': {'query': [1, 0, 0, 0], 'expansion': [1, 0, 0, 0]}, 'expansion': {'query': [0, 1, 0, 0]}, 'extraction': {'query': [0, 0, 0, 1], 'expansion': [0, 1, 0, 0]}, 'corpus': {'expansion': [0, 0, 1, 0]}, 'group': {'expansion': [0, 0, 0, 1]}, 'cluster': {'query': [0, 0, 0, 1]}, 'disjunctive': {'query': [0, 0, 1, 0]}, 'set': {'query': [0, 1, 0, 0]}}\n",
      "doc: Probabilistic Query Expansion method using recommended past user queries\n",
      "vecinity matrix: {'probabilistic': {'query': [1, 0, 0, 0], 'expansion': [0, 1, 0, 0]}, 'query': {'expansion': [1, 0, 0, 0]}, 'expansion': {'query': [1, 0, 0, 0]}, 'method': {'query': [0, 1, 0, 1], 'expansion': [1, 0, 0, 0]}, 'recommended': {'query': [0, 0, 2, 0], 'expansion': [0, 1, 0, 0]}, 'past': {'query': [0, 1, 0, 1], 'expansion': [0, 0, 1, 0]}, 'user': {'query': [1, 0, 0, 0], 'expansion': [0, 0, 0, 1]}}\n",
      "vecinity matrix: {'plenty': {'query': [1, 0, 0, 0], 'expansion': [0, 1, 0, 0]}, 'query': {'expansion': [1, 1, 0, 0]}, 'expansion': {'query': [1, 1, 0, 0]}, 'technique': {'query': [0, 1, 0, 0], 'expansion': [1, 0, 0, 0]}, 'proposed': {'query': [0, 0, 1, 0], 'expansion': [0, 1, 0, 0]}, 'solve': {'query': [0, 0, 0, 1], 'expansion': [0, 0, 1, 0]}, 'problem': {'expansion': [0, 0, 0, 1]}, 'new': {'expansion': [0, 0, 0, 1]}, 'challenge': {'expansion': [0, 0, 1, 0]}, 'introduced': {'query': [0, 0, 0, 1], 'expansion': [0, 1, 0, 0]}, 'method': {'query': [0, 0, 1, 0], 'expansion': [1, 0, 0, 0]}, 'user': {'query': [1, 0, 0, 0], 'expansion': [1, 0, 0, 0]}, 'rapid': {'query': [1, 0, 0, 0], 'expansion': [0, 0, 1, 0]}, 'growth': {'query': [0, 1, 0, 0], 'expansion': [0, 0, 0, 1]}, 'size': {'query': [0, 0, 1, 0]}, 'web': {'query': [0, 0, 0, 1]}}\n",
      "vecinity matrix: {'attention': {'query': [0, 0, 0, 1]}, 'improvement': {'query': [0, 0, 1, 0]}, 'precision': {'query': [0, 1, 0, 1]}, 'user': {'query': [1, 0, 1, 0], 'expansion': [0, 0, 0, 1]}, 'query': {'expansion': [1, 0, 1, 0]}, 'probabilistic': {'query': [2, 0, 0, 0], 'expansion': [0, 1, 0, 0]}, 'expansion': {'query': [1, 0, 1, 0]}, 'method': {'query': [0, 1, 0, 1], 'expansion': [1, 0, 0, 0]}}\n",
      "vecinity matrix: {'consists': {'query': [0, 0, 0, 1]}, 'use': {'query': [0, 0, 1, 0]}, 'information': {'query': [0, 1, 0, 0]}, 'contained': {'query': [1, 0, 0, 0]}, 'log': {'query': [1, 0, 0, 1]}, 'includes': {'query': [0, 1, 1, 0]}, 'past': {'query': [0, 1, 1, 0]}, 'user': {'query': [1, 0, 0, 1]}, 'clicked': {'query': [1, 0, 0, 0]}, 'document': {'query': [0, 1, 0, 0]}, 'providing': {'query': [0, 0, 1, 0]}, 'recommendation': {'query': [0, 0, 0, 1]}}\n",
      "vecinity matrix: {'result': {'query': [0, 0, 0, 1]}, 'show': {'query': [0, 0, 1, 0]}, 'precision': {'query': [1, 1, 1, 0]}, 'short': {'query': [2, 0, 1, 0]}, 'increase': {'query': [1, 0, 0, 0]}, 'even': {'query': [0, 1, 0, 0]}, 'add': {'query': [0, 0, 1, 0]}, 'term': {'query': [0, 0, 0, 2]}, 'added': {'query': [0, 0, 1, 0]}, 'affect': {'query': [0, 1, 0, 0]}, 'long': {'query': [1, 0, 0, 0]}, 'much': {'query': [0, 2, 0, 0]}}\n",
      "doc: Acquiring Lexical Knowledge from Query Logs for Query Expansion in Patent Searching\n",
      "vecinity matrix: {'acquiring': {'query': [0, 0, 1, 0]}, 'lexical': {'query': [0, 1, 0, 1]}, 'knowledge': {'query': [1, 0, 1, 0], 'expansion': [0, 0, 0, 1]}, 'query': {'expansion': [1, 0, 1, 0]}, 'log': {'query': [2, 0, 0, 0], 'expansion': [0, 1, 0, 0]}, 'expansion': {'query': [1, 0, 1, 0]}, 'patent': {'query': [0, 1, 0, 1], 'expansion': [1, 0, 0, 0]}, 'searching': {'query': [0, 0, 1, 0], 'expansion': [0, 1, 0, 0]}}\n",
      "vecinity matrix: {'query': {'expansion': [1, 0, 0, 0]}, 'expansion': {'query': [1, 0, 0, 0]}, 'crucial': {'query': [0, 1, 0, 0], 'expansion': [1, 0, 0, 0]}, 'step': {'query': [0, 0, 1, 0], 'expansion': [0, 1, 0, 0]}, 'domain': {'query': [0, 0, 0, 1], 'expansion': [0, 0, 1, 0]}, 'patent': {'expansion': [0, 0, 0, 1]}}\n",
      "vecinity matrix: {'currently': {'query': [0, 1, 0, 0], 'expansion': [0, 0, 1, 0]}, 'automatic': {'query': [1, 0, 0, 0], 'expansion': [0, 1, 0, 0]}, 'query': {'expansion': [1, 0, 0, 0]}, 'expansion': {'query': [1, 0, 0, 0]}, 'patent': {'query': [0, 1, 0, 0], 'expansion': [1, 0, 0, 0]}, 'search': {'query': [0, 0, 1, 0], 'expansion': [0, 1, 0, 0]}, 'mostly': {'query': [0, 0, 0, 1], 'expansion': [0, 0, 1, 0]}, 'based': {'expansion': [0, 0, 0, 1]}}\n",
      "vecinity matrix: {'additional': {'query': [1, 0, 0, 1]}, 'term': {'query': [1, 1, 0, 0]}, 'extracted': {'query': [1, 1, 0, 0]}, 'document': {'query': [1, 0, 0, 1]}, 'based': {'query': [0, 1, 0, 0]}, 'entropy': {'query': [0, 0, 1, 0]}, 'measure': {'query': [0, 0, 0, 1]}}\n",
      "vecinity matrix: {'automate': {'query': [1, 0, 0, 0], 'expansion': [0, 1, 0, 0]}, 'query': {'expansion': [1, 0, 0, 0]}, 'expansion': {'query': [1, 0, 0, 0]}, 'patent': {'query': [0, 1, 1, 0], 'expansion': [1, 0, 0, 0]}, 'searching': {'query': [0, 0, 1, 1], 'expansion': [0, 1, 0, 0]}, 'acquire': {'query': [0, 0, 1, 1], 'expansion': [0, 0, 1, 0]}, 'lexical': {'query': [0, 1, 0, 0], 'expansion': [0, 0, 0, 1]}, 'knowledge': {'query': [1, 0, 0, 0]}, 'log': {'query': [1, 0, 0, 0]}, 'uspto': {'query': [0, 1, 0, 0]}, 'examiner': {'query': [0, 0, 0, 1]}}\n",
      "vecinity matrix: {'result': {'query': [0, 0, 0, 1]}, 'show': {'query': [0, 0, 1, 0], 'expansion': [0, 0, 0, 1]}, 'good': {'query': [0, 1, 0, 0], 'expansion': [0, 0, 1, 0]}, 'performance': {'query': [1, 0, 0, 0], 'expansion': [0, 1, 0, 0]}, 'query': {'expansion': [1, 0, 0, 0]}, 'expansion': {'query': [1, 0, 0, 0]}, 'patent': {'query': [0, 1, 0, 0], 'expansion': [1, 0, 0, 0]}, 'searching': {'query': [0, 0, 1, 0], 'expansion': [0, 1, 0, 0]}, 'lexical': {'query': [0, 0, 0, 1], 'expansion': [0, 0, 1, 0]}, 'database': {'expansion': [0, 0, 0, 1]}}\n",
      "vecinity matrix: {'help': {'query': [0, 0, 1, 0], 'expansion': [0, 0, 0, 1]}, 'improving': {'query': [0, 1, 0, 0], 'expansion': [0, 0, 1, 0]}, 'automated': {'query': [1, 0, 0, 0], 'expansion': [0, 1, 0, 0]}, 'query': {'expansion': [1, 0, 0, 0]}, 'expansion': {'query': [1, 0, 0, 0]}, 'patent': {'query': [0, 1, 0, 0], 'expansion': [1, 0, 0, 0]}, 'searching': {'query': [0, 0, 1, 0], 'expansion': [0, 1, 0, 0]}}\n",
      "doc: Enhancing Video Retrieval: A User Behavior-Based Query Expansion Approach\n",
      "vecinity matrix: {'enhancing': {'query': [0, 0, 0, 1]}, 'video': {'query': [0, 0, 1, 0], 'expansion': [0, 0, 0, 1]}, 'retrieval': {'query': [0, 1, 0, 0], 'expansion': [0, 0, 1, 0]}, 'user': {'query': [1, 0, 0, 0], 'expansion': [0, 1, 0, 0]}, 'query': {'expansion': [1, 0, 0, 0]}, 'expansion': {'query': [1, 0, 0, 0]}, 'approach': {'query': [0, 1, 0, 0], 'expansion': [1, 0, 0, 0]}}\n",
      "vecinity matrix: {'study': {'query': [0, 0, 1, 0]}, 'propose': {'query': [0, 1, 0, 0]}, 'user': {'query': [1, 1, 0, 0]}, 'optimization': {'query': [1, 0, 0, 0]}, 'strategy': {'query': [0, 1, 0, 0]}, 'address': {'query': [0, 0, 1, 1]}, 'commonly': {'query': [0, 0, 1, 1]}, 'observed': {'query': [0, 1, 0, 0]}, 'suboptimal': {'query': [1, 0, 0, 0]}, 'performance': {'query': [1, 0, 0, 0]}, 'experience': {'query': [0, 0, 1, 0]}, 'field': {'query': [0, 0, 0, 1]}}\n",
      "vecinity matrix: {'video': {'query': [0, 0, 0, 1]}, 'retrieval': {'query': [0, 0, 1, 0]}, 'process': {'query': [0, 1, 0, 0]}, 'expand': {'query': [1, 0, 0, 0]}, 'keywords': {'query': [1, 0, 0, 0]}, 'enhancing': {'query': [0, 1, 0, 0]}, 'relevance': {'query': [0, 0, 1, 0]}, 'diversity': {'query': [0, 0, 0, 1]}}\n",
      "vecinity matrix: {}\n",
      "vecinity matrix: {'subsequently': {'query': [0, 1, 0, 0], 'expansion': [0, 0, 1, 0]}, 'automated': {'query': [1, 0, 0, 0], 'expansion': [0, 1, 0, 0]}, 'query': {'expansion': [1, 0, 0, 0]}, 'expansion': {'query': [1, 0, 0, 0]}, 'algorithm': {'query': [0, 1, 0, 0], 'expansion': [1, 0, 0, 0]}, 'effectively': {'query': [0, 0, 1, 0], 'expansion': [0, 1, 0, 0]}, 'applied': {'query': [0, 0, 0, 1], 'expansion': [0, 0, 1, 0]}, 'data': {'expansion': [0, 0, 0, 1]}}\n",
      "vecinity matrix: {}\n",
      "vecinity matrix: {'result': {'query': [0, 0, 0, 1]}, 'demonstrate': {'query': [0, 0, 1, 0], 'expansion': [0, 0, 0, 1]}, 'user': {'query': [0, 1, 0, 0], 'expansion': [0, 0, 1, 0]}, 'driven': {'query': [1, 0, 0, 0], 'expansion': [0, 1, 0, 0]}, 'query': {'expansion': [1, 0, 0, 0]}, 'expansion': {'query': [1, 0, 0, 0]}, 'approach': {'query': [0, 1, 0, 0], 'expansion': [1, 0, 0, 0]}, 'significantly': {'query': [0, 0, 1, 0], 'expansion': [0, 1, 0, 0]}, 'improves': {'query': [0, 0, 0, 1], 'expansion': [0, 0, 1, 0]}, 'accuracy': {'expansion': [0, 0, 0, 1]}}\n",
      "doc: A search log sparseness oriented query expansion method\n",
      "vecinity matrix: {'search': {'query': [0, 0, 0, 1]}, 'log': {'query': [0, 0, 1, 0], 'expansion': [0, 0, 0, 1]}, 'sparseness': {'query': [0, 1, 0, 0], 'expansion': [0, 0, 1, 0]}, 'oriented': {'query': [1, 0, 0, 0], 'expansion': [0, 1, 0, 0]}, 'query': {'expansion': [1, 0, 0, 0]}, 'expansion': {'query': [1, 0, 0, 0]}, 'method': {'query': [0, 1, 0, 0], 'expansion': [1, 0, 0, 0]}}\n",
      "vecinity matrix: {'query': {'expansion': [1, 0, 0, 0]}, 'expansion': {'query': [1, 0, 0, 0]}, 'method': {'query': [0, 1, 0, 0], 'expansion': [1, 0, 0, 0]}, 'based': {'query': [0, 0, 1, 0], 'expansion': [0, 1, 0, 0]}, 'search': {'query': [0, 0, 0, 1], 'expansion': [0, 0, 1, 0]}, 'log': {'expansion': [0, 0, 0, 1]}}\n",
      "vecinity matrix: {'search': {'query': [0, 0, 0, 1], 'expansion': [0, 0, 0, 1]}, 'log': {'query': [0, 0, 1, 0], 'expansion': [0, 0, 0, 1]}, 'sparse': {'query': [0, 1, 0, 0], 'expansion': [0, 0, 1, 0]}, 'kind': {'query': [1, 0, 0, 0], 'expansion': [0, 1, 0, 0]}, 'query': {'expansion': [1, 0, 0, 0]}, 'expansion': {'query': [1, 0, 0, 0]}, 'method': {'query': [0, 1, 0, 0], 'expansion': [1, 0, 0, 0]}, 'poor': {'query': [0, 0, 1, 0], 'expansion': [0, 1, 0, 0]}, 'quality': {'query': [0, 0, 0, 1], 'expansion': [0, 0, 1, 0]}}\n",
      "vecinity matrix: {'search': {'query': [0, 0, 0, 1]}, 'log': {'query': [0, 0, 1, 0]}, 'sparseness': {'query': [0, 1, 0, 0]}, 'oriented': {'query': [1, 0, 0, 0]}, 'extension': {'query': [1, 0, 0, 0]}, 'method': {'query': [0, 1, 0, 0]}}\n",
      "vecinity matrix: {'data': {'expansion': [0, 0, 1, 1]}, 'sparseness': {'expansion': [0, 0, 1, 0]}, 'method': {'expansion': [0, 1, 0, 0]}, 'selects': {'expansion': [1, 0, 0, 0]}, 'term': {'expansion': [3, 0, 1, 0]}, 'high': {'expansion': [0, 2, 0, 0]}, 'performance': {'expansion': [1, 0, 1, 0]}, 'given': {'expansion': [0, 1, 0, 0]}, 'local': {'expansion': [0, 0, 1, 0]}, 'context': {'expansion': [0, 0, 0, 1]}, 'sparse': {'expansion': [0, 0, 0, 1]}, 'set': {'expansion': [0, 1, 0, 0]}, 'providing': {'expansion': [1, 0, 0, 0]}, 'higher': {'query': [0, 0, 0, 1], 'expansion': [0, 1, 0, 0]}, 'quality': {'query': [0, 0, 1, 0], 'expansion': [0, 0, 1, 0]}, 'user': {'query': [0, 1, 0, 0], 'expansion': [0, 0, 0, 1]}, 'initial': {'query': [1, 0, 0, 0]}}\n",
      "vecinity matrix: {}\n",
      "doc: Combining Query Reformulation and Re-ranking to Improve Query Expansion in Chinese EMR Retrieval\n",
      "vecinity matrix: {'combining': {'query': [1, 0, 0, 1]}, 'query': {'expansion': [1, 0, 0, 1]}, 'reformulation': {'query': [1, 1, 0, 0], 'expansion': [0, 0, 1, 0]}, 'improve': {'query': [1, 1, 0, 0], 'expansion': [0, 1, 0, 0]}, 'expansion': {'query': [1, 0, 0, 1]}, 'chinese': {'query': [0, 1, 0, 0], 'expansion': [1, 0, 0, 0]}, 'emr': {'query': [0, 0, 1, 0], 'expansion': [0, 1, 0, 0]}, 'retrieval': {'query': [0, 0, 0, 1], 'expansion': [0, 0, 1, 0]}}\n",
      "vecinity matrix: {'method': {'query': [1, 0, 0, 0], 'expansion': [0, 1, 0, 0]}, 'query': {'expansion': [1, 0, 0, 0]}, 'expansion': {'query': [1, 0, 0, 0]}, 'qe': {'query': [0, 1, 0, 0], 'expansion': [1, 0, 0, 0]}, 'achieved': {'query': [0, 0, 1, 0], 'expansion': [0, 1, 0, 0]}, 'significant': {'query': [0, 0, 0, 1], 'expansion': [0, 0, 1, 0]}, 'performance': {'expansion': [0, 0, 0, 1]}}\n",
      "vecinity matrix: {'pity': {'expansion': [0, 0, 1, 0]}, 'direct': {'expansion': [0, 1, 0, 0]}, 'addition': {'expansion': [1, 0, 0, 0]}, 'expansion': {'query': [0, 0, 0, 1]}, 'term': {'query': [0, 0, 1, 0], 'expansion': [1, 0, 0, 0]}, 'may': {'query': [0, 1, 0, 0], 'expansion': [0, 1, 0, 0]}, 'cause': {'query': [1, 0, 0, 0], 'expansion': [0, 0, 1, 0]}, 'query': {'expansion': [0, 0, 0, 1]}, 'drift': {'query': [1, 0, 0, 0]}, 'decrease': {'query': [0, 1, 0, 0]}, 'precision': {'query': [0, 0, 1, 0]}, 'emr': {'query': [0, 0, 0, 1]}}\n",
      "vecinity matrix: {'solve': {'query': [0, 0, 0, 1]}, 'issue': {'query': [0, 0, 1, 0]}, 'combine': {'query': [0, 1, 0, 0]}, 'method': {'query': [1, 0, 0, 0]}, 'reformulation': {'query': [1, 0, 0, 0]}, 'improve': {'query': [0, 1, 0, 0]}, 'performance': {'query': [0, 0, 1, 0]}, 'qe': {'query': [0, 0, 0, 1]}}\n",
      "vecinity matrix: {'chinese': {'expansion': [0, 0, 0, 1]}, 'medical': {'expansion': [0, 0, 1, 0]}, 'knowledge': {'expansion': [0, 1, 0, 0]}, 'graph': {'expansion': [1, 0, 0, 1]}, 'term': {'expansion': [2, 1, 0, 1]}, 'weight': {'expansion': [1, 1, 0, 0]}, 'calculated': {'expansion': [0, 1, 0, 0]}, 'combination': {'expansion': [0, 0, 1, 0]}, 'semantic': {'expansion': [0, 0, 0, 1]}}\n",
      "vecinity matrix: {'query': {'expansion': [0, 1, 0, 0]}, 'reformulated': {'query': [1, 0, 0, 0], 'expansion': [1, 0, 0, 0]}, 'expansion': {'query': [0, 1, 0, 0]}, 'term': {'query': [0, 0, 1, 0], 'expansion': [1, 0, 0, 0]}, 'emr': {'query': [0, 0, 0, 2], 'expansion': [0, 1, 0, 0]}, 'document': {'query': [0, 0, 1, 0], 'expansion': [0, 0, 1, 0]}, 'retrieved': {'query': [0, 1, 0, 0], 'expansion': [0, 0, 0, 1]}, 'expanded': {'query': [1, 0, 0, 0]}}\n",
      "vecinity matrix: {}\n",
      "vecinity matrix: {}\n",
      "vecinity matrix: {'show': {'query': [0, 1, 0, 0]}, 'compared': {'query': [0, 0, 0, 1]}, 'baseline': {'query': [0, 0, 1, 0]}, 'combination': {'query': [1, 0, 0, 0], 'expansion': [0, 0, 0, 1]}, 'query': {'expansion': [0, 0, 1, 0]}, 'reformulation': {'query': [1, 0, 0, 0], 'expansion': [0, 1, 0, 0]}, 'differentiate': {'query': [0, 1, 0, 0], 'expansion': [1, 0, 0, 0]}, 'expansion': {'query': [0, 0, 1, 0]}, 'term': {'query': [0, 0, 0, 1], 'expansion': [1, 0, 0, 0]}, 'different': {'expansion': [0, 1, 0, 0]}, 'category': {'expansion': [0, 0, 1, 0]}, 'maximize': {'expansion': [0, 0, 0, 1]}}\n",
      "doc: An ontological approach for SQL query expansion\n",
      "vecinity matrix: {'ontological': {'query': [0, 0, 1, 0], 'expansion': [0, 0, 0, 1]}, 'approach': {'query': [0, 1, 0, 0], 'expansion': [0, 0, 1, 0]}, 'sql': {'query': [1, 0, 0, 0], 'expansion': [0, 1, 0, 0]}, 'query': {'expansion': [1, 0, 0, 0]}, 'expansion': {'query': [1, 0, 0, 0]}}\n",
      "vecinity matrix: {}\n",
      "vecinity matrix: {}\n",
      "vecinity matrix: {}\n",
      "vecinity matrix: {'help': {'query': [0, 0, 0, 1]}, 'user': {'query': [0, 0, 1, 0]}, 'search': {'query': [0, 1, 0, 0]}, 'initial': {'query': [1, 0, 0, 0]}, 'return': {'query': [1, 0, 0, 0]}, 'result': {'query': [0, 1, 0, 0]}}\n",
      "vecinity matrix: {'propose': {'query': [0, 0, 0, 1]}, 'ontological': {'query': [0, 0, 1, 0], 'expansion': [0, 0, 0, 1]}, 'approach': {'query': [0, 1, 0, 0], 'expansion': [0, 0, 1, 0]}, 'sql': {'query': [1, 0, 0, 0], 'expansion': [0, 1, 0, 0]}, 'query': {'expansion': [1, 0, 0, 0], 'refinement': [0, 0, 0, 1]}, 'expansion': {'query': [1, 0, 0, 0], 'refinement': [0, 0, 1, 0]}, 'based': {'query': [0, 1, 0, 0], 'expansion': [1, 0, 0, 0], 'refinement': [0, 1, 0, 0]}, 'different': {'query': [0, 0, 1, 0], 'expansion': [0, 1, 0, 0], 'refinement': [1, 0, 0, 0]}, 'refinement': {'query': [0, 0, 0, 1], 'expansion': [0, 0, 1, 0]}, 'type': {'expansion': [0, 0, 0, 1], 'refinement': [1, 0, 0, 0]}}\n",
      "vecinity matrix: {}\n",
      "doc: Ontology-Driven Query Expansion Using Map/Reduce Framework to Facilitate Federated Queries\n",
      "vecinity matrix: {'query': {'expansion': [1, 0, 0, 1]}, 'expansion': {'query': [1, 0, 0, 1]}, 'framework': {'query': [0, 1, 1, 0], 'expansion': [1, 0, 0, 0]}, 'facilitate': {'query': [0, 1, 1, 0], 'expansion': [0, 1, 0, 0]}, 'federated': {'query': [1, 0, 0, 1], 'expansion': [0, 0, 1, 0]}}\n",
      "vecinity matrix: {'distributed': {'query': [0, 0, 0, 1]}, 'federated': {'query': [0, 0, 1, 0], 'expansion': [0, 0, 0, 1]}, 'architecture': {'query': [0, 1, 0, 0], 'expansion': [0, 0, 1, 0]}, 'robust': {'query': [1, 0, 0, 0], 'expansion': [0, 1, 0, 0]}, 'query': {'expansion': [1, 0, 0, 0]}, 'expansion': {'query': [1, 0, 0, 0]}, 'great': {'query': [0, 1, 0, 0], 'expansion': [1, 0, 0, 0]}, 'impact': {'query': [0, 0, 1, 0], 'expansion': [0, 1, 0, 0]}, 'performance': {'query': [0, 0, 0, 1], 'expansion': [0, 0, 1, 0]}, 'information': {'expansion': [0, 0, 0, 1]}}\n",
      "vecinity matrix: {'aim': {'query': [0, 1, 0, 0], 'expansion': [0, 0, 1, 0]}, 'determine': {'query': [1, 0, 0, 0], 'expansion': [0, 1, 0, 0]}, 'query': {'expansion': [1, 0, 0, 0]}, 'expansion': {'query': [1, 0, 0, 0]}, 'term': {'query': [0, 1, 0, 0], 'expansion': [1, 0, 0, 0]}, 'different': {'query': [0, 0, 1, 0], 'expansion': [0, 1, 0, 0]}, 'weighting': {'query': [0, 0, 0, 1], 'expansion': [0, 0, 1, 0]}, 'technique': {'expansion': [0, 0, 0, 1]}}\n",
      "vecinity matrix: {'consider': {'query': [0, 0, 0, 1]}, 'individual': {'query': [0, 0, 1, 0]}, 'ontology': {'query': [0, 1, 0, 0]}, 'user': {'query': [1, 0, 0, 0]}, 'query': {'expansion': [0, 0, 0, 1]}, 'keywords': {'query': [1, 0, 0, 0], 'expansion': [0, 0, 1, 0]}, 'determine': {'query': [0, 1, 0, 0], 'expansion': [0, 1, 0, 0]}, 'basic': {'query': [0, 0, 1, 0], 'expansion': [1, 0, 0, 0]}, 'expansion': {'query': [0, 0, 0, 1]}, 'term': {'expansion': [1, 0, 0, 0]}, 'bet': {'expansion': [0, 1, 0, 0]}, 'number': {'expansion': [0, 0, 1, 0]}, 'semantic': {'expansion': [0, 0, 0, 1]}}\n",
      "vecinity matrix: {}\n",
      "vecinity matrix: {}\n",
      "doc: Learning query expansion from association rules between terms\n",
      "vecinity matrix: {'learning': {'query': [1, 0, 0, 0], 'expansion': [0, 1, 0, 0]}, 'query': {'expansion': [1, 0, 0, 0]}, 'expansion': {'query': [1, 0, 0, 0]}, 'association': {'query': [0, 1, 0, 0], 'expansion': [1, 0, 0, 0]}, 'rule': {'query': [0, 0, 1, 0], 'expansion': [0, 1, 0, 0]}, 'term': {'query': [0, 0, 0, 1], 'expansion': [0, 0, 1, 0]}}\n",
      "vecinity matrix: {'query': {'expansion': [1, 0, 0, 0]}, 'expansion': {'query': [1, 0, 0, 0]}, 'technique': {'query': [0, 1, 0, 0], 'expansion': [1, 0, 0, 0]}, 'offer': {'query': [0, 0, 1, 0], 'expansion': [0, 1, 0, 0]}, 'interesting': {'query': [0, 0, 0, 1], 'expansion': [0, 0, 1, 0]}, 'solution': {'expansion': [0, 0, 0, 1]}, 'obtaining': {'query': [0, 0, 0, 1]}, 'complete': {'query': [0, 0, 1, 0]}, 'answer': {'query': [0, 1, 0, 0]}, 'user': {'query': [1, 0, 0, 0]}, 'preserving': {'query': [1, 0, 0, 0]}, 'quality': {'query': [0, 1, 0, 0]}, 'retained': {'query': [0, 0, 1, 0]}, 'document': {'query': [0, 0, 0, 1]}}\n",
      "vecinity matrix: {'choice': {'query': [0, 0, 0, 1]}, 'added': {'query': [0, 0, 1, 0]}, 'term': {'query': [0, 1, 0, 0]}, 'initial': {'query': [1, 0, 0, 0]}}\n",
      "vecinity matrix: {}\n",
      "vecinity matrix: {'order': {'query': [0, 0, 0, 1]}, 'select': {'query': [0, 0, 1, 0]}, 'optimal': {'query': [0, 1, 0, 0]}, 'combination': {'query': [1, 0, 0, 0]}, 'term': {'query': [1, 0, 0, 0]}, 'generic': {'query': [0, 1, 0, 0]}, 'basis': {'query': [0, 0, 1, 0]}, 'propose': {'query': [0, 0, 0, 1]}}\n",
      "vecinity matrix: {'set': {'expansion': [1, 0, 0, 0]}, 'association': {'query': [0, 0, 0, 1]}, 'rule': {'query': [0, 0, 1, 0]}, 'order': {'expansion': [0, 0, 0, 1]}, 'find': {'expansion': [0, 0, 1, 0]}, 'optimal': {'expansion': [0, 1, 0, 0]}, 'term': {'expansion': [1, 0, 0, 0]}, 'improving': {'expansion': [0, 1, 0, 0]}, 'map': {'expansion': [0, 0, 1, 0]}, 'search': {'expansion': [0, 0, 0, 1]}, 'used': {'query': [0, 1, 0, 0]}, 'expanding': {'query': [1, 0, 0, 0]}}\n",
      "vecinity matrix: {}\n",
      "vecinity matrix: {'observation': {'query': [0, 0, 0, 1]}, 'hybridization': {'query': [0, 0, 1, 0], 'expansion': [0, 0, 0, 1]}, 'textmining': {'query': [0, 1, 0, 0], 'expansion': [0, 0, 1, 0]}, 'technique': {'query': [1, 0, 0, 0], 'expansion': [0, 1, 0, 0]}, 'query': {'expansion': [1, 0, 0, 0]}, 'expansion': {'query': [1, 0, 0, 0]}, 'intelligent': {'query': [0, 1, 0, 0], 'expansion': [1, 0, 0, 0]}, 'way': {'query': [0, 0, 1, 0], 'expansion': [0, 1, 0, 0]}, 'allows': {'query': [0, 0, 0, 1], 'expansion': [0, 0, 1, 0]}, 'incorporate': {'expansion': [0, 0, 0, 1]}}\n",
      "vecinity matrix: {}\n"
     ]
    }
   ],
   "source": [
    "for d in ranking.get_documents():\n",
    "    print(f\"doc: {d.get_title()}\")\n",
    "    for s in d.get_sentences():\n",
    "        print(f\"vecinity matrix: {s.get_vicinity_matrix()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBQUERY: query AND (expansion OR refinement)\n",
      "TERM: technique ; PONDERATION: 11.4 ; DISTANCE: 2.1\n",
      "TERM: method ; PONDERATION: 10.7 ; DISTANCE: 1.8\n",
      "TERM: user ; PONDERATION: 9.6 ; DISTANCE: 2.2\n",
      "TERM: expansion ; PONDERATION: 8.5 ; DISTANCE: 2.4\n",
      "TERM: patent ; PONDERATION: 8.4 ; DISTANCE: 1.7\n",
      "TERM: refinement ; PONDERATION: 7.9 ; DISTANCE: 2.7\n",
      "TERM: term ; PONDERATION: 7.0 ; DISTANCE: 1.9\n",
      "TERM: suggestion ; PONDERATION: 7.0 ; DISTANCE: 1.9\n",
      "TERM: searching ; PONDERATION: 6.6 ; DISTANCE: 2.6\n",
      "TERM: approach ; PONDERATION: 4.9 ; DISTANCE: 1.9\n",
      "TERM: log ; PONDERATION: 4.4 ; DISTANCE: 2.7\n",
      "TERM: search ; PONDERATION: 4.2 ; DISTANCE: 3.3\n",
      "TERM: probabilistic ; PONDERATION: 3.7 ; DISTANCE: 1.5\n",
      "TERM: basic ; PONDERATION: 3.2 ; DISTANCE: 2.7\n",
      "TERM: lexical ; PONDERATION: 3.2 ; DISTANCE: 3.2\n",
      "TERM: automated ; PONDERATION: 3.0 ; DISTANCE: 1.5\n",
      "TERM: based ; PONDERATION: 2.8 ; DISTANCE: 2.0\n",
      "TERM: retrieval ; PONDERATION: 2.6 ; DISTANCE: 2.9\n",
      "TERM: quality ; PONDERATION: 2.6 ; DISTANCE: 3.2\n",
      "TERM: phrase ; PONDERATION: 2.6 ; DISTANCE: 1.8\n",
      "TERM: reformulation ; PONDERATION: 2.5 ; DISTANCE: 1.8\n",
      "TERM: emr ; PONDERATION: 2.5 ; DISTANCE: 2.8\n",
      "TERM: modification ; PONDERATION: 2.5 ; DISTANCE: 2.6\n",
      "TERM: performance ; PONDERATION: 2.5 ; DISTANCE: 2.2\n",
      "TERM: different ; PONDERATION: 2.4 ; DISTANCE: 2.2\n",
      "TERM: survey ; PONDERATION: 2.3 ; DISTANCE: 2.0\n",
      "TERM: make ; PONDERATION: 2.3 ; DISTANCE: 2.1\n",
      "TERM: sql ; PONDERATION: 2.0 ; DISTANCE: 1.5\n",
      "TERM: ontological ; PONDERATION: 2.0 ; DISTANCE: 3.5\n",
      "TERM: detailed ; PONDERATION: 2.0 ; DISTANCE: 2.5\n",
      "TERM: comparison ; PONDERATION: 2.0 ; DISTANCE: 3.5\n",
      "TERM: discus ; PONDERATION: 2.0 ; DISTANCE: 3.5\n",
      "TERM: recommended ; PONDERATION: 2.0 ; DISTANCE: 2.6\n",
      "TERM: past ; PONDERATION: 2.0 ; DISTANCE: 3.0\n",
      "TERM: federated ; PONDERATION: 1.9 ; DISTANCE: 3.1\n",
      "TERM: many ; PONDERATION: 1.9 ; DISTANCE: 3.0\n",
      "TERM: extraction ; PONDERATION: 1.9 ; DISTANCE: 3.0\n",
      "TERM: acquire ; PONDERATION: 1.8 ; DISTANCE: 3.3\n",
      "TERM: knowledge ; PONDERATION: 1.8 ; DISTANCE: 2.9\n",
      "TERM: determine ; PONDERATION: 1.8 ; DISTANCE: 1.8\n",
      "TERM: rapid ; PONDERATION: 1.7 ; DISTANCE: 2.0\n",
      "TERM: plenty ; PONDERATION: 1.7 ; DISTANCE: 1.5\n",
      "TERM: introduced ; PONDERATION: 1.7 ; DISTANCE: 3.0\n",
      "TERM: solve ; PONDERATION: 1.7 ; DISTANCE: 3.5\n",
      "TERM: proposed ; PONDERATION: 1.7 ; DISTANCE: 2.5\n",
      "TERM: growth ; PONDERATION: 1.7 ; DISTANCE: 3.0\n",
      "TERM: help ; PONDERATION: 1.6 ; DISTANCE: 3.5\n",
      "TERM: show ; PONDERATION: 1.6 ; DISTANCE: 3.5\n",
      "TERM: improving ; PONDERATION: 1.6 ; DISTANCE: 2.5\n",
      "TERM: crucial ; PONDERATION: 1.6 ; DISTANCE: 1.5\n",
      "TERM: domain ; PONDERATION: 1.6 ; DISTANCE: 3.5\n",
      "TERM: automatic ; PONDERATION: 1.6 ; DISTANCE: 1.5\n",
      "TERM: good ; PONDERATION: 1.6 ; DISTANCE: 2.5\n",
      "TERM: mostly ; PONDERATION: 1.6 ; DISTANCE: 3.5\n",
      "TERM: automate ; PONDERATION: 1.6 ; DISTANCE: 1.5\n",
      "TERM: step ; PONDERATION: 1.6 ; DISTANCE: 2.5\n",
      "TERM: currently ; PONDERATION: 1.6 ; DISTANCE: 2.5\n",
      "TERM: algorithm ; PONDERATION: 1.4 ; DISTANCE: 1.5\n",
      "TERM: video ; PONDERATION: 1.4 ; DISTANCE: 3.5\n",
      "TERM: demonstrate ; PONDERATION: 1.4 ; DISTANCE: 3.5\n",
      "TERM: subsequently ; PONDERATION: 1.4 ; DISTANCE: 2.5\n",
      "TERM: driven ; PONDERATION: 1.4 ; DISTANCE: 1.5\n",
      "TERM: improves ; PONDERATION: 1.4 ; DISTANCE: 3.5\n",
      "TERM: applied ; PONDERATION: 1.4 ; DISTANCE: 3.5\n",
      "TERM: effectively ; PONDERATION: 1.4 ; DISTANCE: 2.5\n",
      "TERM: significantly ; PONDERATION: 1.4 ; DISTANCE: 2.5\n",
      "TERM: improve ; PONDERATION: 1.3 ; DISTANCE: 1.7\n",
      "TERM: sparseness ; PONDERATION: 1.3 ; DISTANCE: 2.5\n",
      "TERM: higher ; PONDERATION: 1.3 ; DISTANCE: 3.0\n",
      "TERM: sparse ; PONDERATION: 1.3 ; DISTANCE: 2.5\n",
      "TERM: oriented ; PONDERATION: 1.3 ; DISTANCE: 1.5\n",
      "TERM: poor ; PONDERATION: 1.3 ; DISTANCE: 2.5\n",
      "TERM: kind ; PONDERATION: 1.3 ; DISTANCE: 1.5\n",
      "TERM: significant ; PONDERATION: 1.2 ; DISTANCE: 3.5\n",
      "TERM: reformulated ; PONDERATION: 1.2 ; DISTANCE: 1.0\n",
      "TERM: differentiate ; PONDERATION: 1.2 ; DISTANCE: 1.5\n",
      "TERM: document ; PONDERATION: 1.2 ; DISTANCE: 3.0\n",
      "TERM: combination ; PONDERATION: 1.2 ; DISTANCE: 2.5\n",
      "TERM: retrieved ; PONDERATION: 1.2 ; DISTANCE: 3.0\n",
      "TERM: achieved ; PONDERATION: 1.2 ; DISTANCE: 2.5\n",
      "TERM: chinese ; PONDERATION: 1.2 ; DISTANCE: 1.5\n",
      "TERM: may ; PONDERATION: 1.2 ; DISTANCE: 2.0\n",
      "TERM: cause ; PONDERATION: 1.2 ; DISTANCE: 2.0\n",
      "TERM: qe ; PONDERATION: 1.2 ; DISTANCE: 1.5\n",
      "TERM: facilitate ; PONDERATION: 1.0 ; DISTANCE: 2.3\n",
      "TERM: framework ; PONDERATION: 1.0 ; DISTANCE: 1.8\n",
      "TERM: aim ; PONDERATION: 0.9 ; DISTANCE: 2.5\n",
      "TERM: great ; PONDERATION: 0.9 ; DISTANCE: 1.5\n",
      "TERM: keywords ; PONDERATION: 0.9 ; DISTANCE: 2.0\n",
      "TERM: architecture ; PONDERATION: 0.9 ; DISTANCE: 2.5\n",
      "TERM: weighting ; PONDERATION: 0.9 ; DISTANCE: 3.5\n",
      "TERM: robust ; PONDERATION: 0.9 ; DISTANCE: 1.5\n",
      "TERM: impact ; PONDERATION: 0.9 ; DISTANCE: 2.5\n",
      "TERM: association ; PONDERATION: 0.7 ; DISTANCE: 1.5\n",
      "TERM: offer ; PONDERATION: 0.7 ; DISTANCE: 2.5\n",
      "TERM: way ; PONDERATION: 0.7 ; DISTANCE: 2.5\n",
      "TERM: hybridization ; PONDERATION: 0.7 ; DISTANCE: 3.5\n",
      "TERM: interesting ; PONDERATION: 0.7 ; DISTANCE: 3.5\n",
      "TERM: learning ; PONDERATION: 0.7 ; DISTANCE: 1.5\n",
      "TERM: rule ; PONDERATION: 0.7 ; DISTANCE: 2.5\n",
      "TERM: allows ; PONDERATION: 0.7 ; DISTANCE: 3.5\n",
      "TERM: intelligent ; PONDERATION: 0.7 ; DISTANCE: 1.5\n",
      "TERM: textmining ; PONDERATION: 0.7 ; DISTANCE: 2.5\n"
     ]
    }
   ],
   "source": [
    "#Show graphs from the ranking class\n",
    "print(ranking.get_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: node '0', graph 'G' size too small for label\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 10.0.1 (20240210.2158)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"642pt\" height=\"573pt\"\n",
       " viewBox=\"0.00 0.00 642.31 572.59\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 568.59)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-568.59 638.31,-568.59 638.31,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"#c1cdcd\" stroke=\"black\" cx=\"326.43\" cy=\"-305\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"326.43\" y=\"-301.12\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">query AND (expansion OR refinement)</text>\n",
       "</g>\n",
       "<!-- &#39;1&#39; -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>&#39;1&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"8.2\" cx=\"167.56\" cy=\"-237.05\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"167.56\" y=\"-233.17\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">technique</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;1&#39; -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;1&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M302.98,-294.97C273.98,-282.57 224.72,-261.5 194.29,-248.48\"/>\n",
       "<text text-anchor=\"middle\" x=\"240.01\" y=\"-274.17\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2.3</text>\n",
       "</g>\n",
       "<!-- &#39;2&#39; -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>&#39;2&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"6.95\" cx=\"428.03\" cy=\"-222.28\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"428.03\" y=\"-218.4\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">suggestion</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;2&#39; -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;2&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M346.02,-289.05C363.32,-274.96 388.5,-254.46 406.39,-239.9\"/>\n",
       "<text text-anchor=\"middle\" x=\"367.58\" y=\"-266.92\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.9</text>\n",
       "</g>\n",
       "<!-- &#39;3&#39; -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>&#39;3&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"2.48\" cx=\"366.72\" cy=\"-539.39\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"366.72\" y=\"-535.52\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">modification</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;3&#39; -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;3&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M330.74,-330.08C338.45,-374.96 354.54,-468.52 362.32,-513.78\"/>\n",
       "<text text-anchor=\"middle\" x=\"337.9\" y=\"-424.38\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2.6</text>\n",
       "</g>\n",
       "<!-- &#39;4&#39; -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>&#39;4&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"2.3\" cx=\"444.81\" cy=\"-398.49\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"444.81\" y=\"-394.62\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">survey</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;4&#39; -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;4&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M346.51,-320.86C368.28,-338.05 402.82,-365.33 424.63,-382.55\"/>\n",
       "<text text-anchor=\"middle\" x=\"376.94\" y=\"-354.15\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2.0</text>\n",
       "</g>\n",
       "<!-- &#39;5&#39; -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>&#39;5&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"2.3\" cx=\"230.6\" cy=\"-424.23\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"230.6\" y=\"-420.35\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">make</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;5&#39; -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;5&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M310.39,-324.95C292.8,-346.83 264.74,-381.75 247.01,-403.8\"/>\n",
       "<text text-anchor=\"middle\" x=\"270.07\" y=\"-366.83\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2.1</text>\n",
       "</g>\n",
       "<!-- &#39;6&#39; -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>&#39;6&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"2.3\" cx=\"609.11\" cy=\"-284.82\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"609.11\" y=\"-280.95\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">basic</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;6&#39; -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;6&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M352.01,-303.17C405.69,-299.34 529.57,-290.5 583.38,-286.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"459.07\" y=\"-297.36\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3.0</text>\n",
       "</g>\n",
       "<!-- &#39;7&#39; -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>&#39;7&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"2\" cx=\"372.36\" cy=\"-92.1\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"372.36\" y=\"-88.22\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">detailed</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;7&#39; -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;7&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M331.78,-280.16C340.59,-239.35 358.02,-158.57 366.89,-117.44\"/>\n",
       "<text text-anchor=\"middle\" x=\"340.71\" y=\"-201.25\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2.5</text>\n",
       "</g>\n",
       "<!-- &#39;8&#39; -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>&#39;8&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"2\" cx=\"25.2\" cy=\"-425.5\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"25.2\" y=\"-421.62\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">comparison</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;8&#39; -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;8&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M302.79,-314.45C246.62,-336.92 105.62,-393.33 49.14,-415.92\"/>\n",
       "<text text-anchor=\"middle\" x=\"167.34\" y=\"-367.63\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3.5</text>\n",
       "</g>\n",
       "<!-- &#39;9&#39; -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>&#39;9&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"2\" cx=\"160.44\" cy=\"-25.2\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"160.44\" y=\"-21.32\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">discus</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;9&#39; -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;9&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M313.4,-283.04C282.45,-230.87 204.75,-99.9 173.63,-47.44\"/>\n",
       "<text text-anchor=\"middle\" x=\"234.89\" y=\"-167.69\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3.5</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Graph at 0x2305b2cb650>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_graph1 = ranking.get_document_by_ranking_position(1).get_graph().get_graph_viz('0.7', 'deepskyblue')\n",
    "visual_graph1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: node '0', graph 'G' size too small for label\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 10.0.1 (20240210.2158)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"277pt\" height=\"528pt\"\n",
       " viewBox=\"0.00 0.00 276.83 528.14\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 524.14)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-524.14 272.83,-524.14 272.83,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"#c1cdcd\" stroke=\"black\" cx=\"159.05\" cy=\"-262.89\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"159.05\" y=\"-259.01\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">query AND (expansion OR refinement)</text>\n",
       "</g>\n",
       "<!-- &#39;1&#39; -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>&#39;1&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"2.58\" cx=\"25.2\" cy=\"-270.08\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"25.2\" y=\"-266.21\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">phrase</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;1&#39; -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;1&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M133.56,-264.26C109.89,-265.53 74.83,-267.41 51.05,-268.69\"/>\n",
       "<text text-anchor=\"middle\" x=\"83.68\" y=\"-268.93\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.8</text>\n",
       "</g>\n",
       "<!-- &#39;2&#39; -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>&#39;2&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"1.86\" cx=\"222.24\" cy=\"-25.2\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"222.24\" y=\"-21.32\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">many</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;2&#39; -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;2&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M165.57,-238.35C177.68,-192.8 203.51,-95.68 215.66,-49.96\"/>\n",
       "<text text-anchor=\"middle\" x=\"181.99\" y=\"-146.61\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3.0</text>\n",
       "</g>\n",
       "<!-- &#39;3&#39; -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>&#39;3&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"1.86\" cx=\"243.63\" cy=\"-494.94\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"243.63\" y=\"-491.07\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">extraction</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;3&#39; -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;3&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M167.78,-286.85C184.03,-331.43 218.73,-426.63 234.94,-471.11\"/>\n",
       "<text text-anchor=\"middle\" x=\"192.74\" y=\"-381.43\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3.0</text>\n",
       "</g>\n",
       "<!-- &#39;4&#39; -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>&#39;4&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"1.86\" cx=\"230.43\" cy=\"-261.11\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"230.43\" y=\"-257.24\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">term</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;4&#39; -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;4&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M184.42,-262.26C191.15,-262.09 198.42,-261.91 205.15,-261.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"194.78\" y=\"-248.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.0</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Graph at 0x230596eeba0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_graph2 = ranking.get_document_by_ranking_position(2).get_graph().get_graph_viz('0.7', 'deepskyblue')\n",
    "visual_graph2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: node '0', graph 'G' size too small for label\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 10.0.1 (20240210.2158)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"542pt\" height=\"478pt\"\n",
       " viewBox=\"0.00 0.00 542.17 478.17\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 474.17)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-474.17 538.17,-474.17 538.17,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"#c1cdcd\" stroke=\"black\" cx=\"197.99\" cy=\"-252.91\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"197.99\" y=\"-249.03\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">query AND (expansion OR refinement)</text>\n",
       "</g>\n",
       "<!-- &#39;1&#39; -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>&#39;1&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"11.4\" cx=\"30.46\" cy=\"-336.47\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"30.46\" y=\"-332.6\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">technique</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;1&#39; -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;1&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M175.05,-264.35C144.49,-279.59 90.5,-306.53 57.85,-322.81\"/>\n",
       "<text text-anchor=\"middle\" x=\"107.82\" y=\"-296.03\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2.1</text>\n",
       "</g>\n",
       "<!-- &#39;2&#39; -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>&#39;2&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"10.74\" cx=\"188.31\" cy=\"-124.92\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"188.31\" y=\"-121.05\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">method</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;2&#39; -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;2&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M196.06,-227.32C194.48,-206.45 192.25,-176.95 190.58,-154.97\"/>\n",
       "<text text-anchor=\"middle\" x=\"184.69\" y=\"-193.59\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.8</text>\n",
       "</g>\n",
       "<!-- &#39;3&#39; -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>&#39;3&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"9.6\" cx=\"258.23\" cy=\"-444.97\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"258.23\" y=\"-441.09\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">user</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;3&#39; -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;3&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M205.62,-277.23C216.8,-312.86 237.57,-379.09 249.4,-416.79\"/>\n",
       "<text text-anchor=\"middle\" x=\"218.88\" y=\"-349.46\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2.2</text>\n",
       "</g>\n",
       "<!-- &#39;4&#39; -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>&#39;4&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"8.38\" cx=\"300.09\" cy=\"-316.65\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"300.09\" y=\"-312.78\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">patent</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;4&#39; -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;4&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M219.64,-266.43C236.04,-276.66 258.56,-290.72 275.61,-301.36\"/>\n",
       "<text text-anchor=\"middle\" x=\"239\" y=\"-286.34\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.7</text>\n",
       "</g>\n",
       "<!-- &#39;5&#39; -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>&#39;5&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"6.96\" cx=\"139.55\" cy=\"-391.35\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"139.55\" y=\"-387.48\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">term</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;5&#39; -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;5&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M188.08,-276.39C177.66,-301.08 161.3,-339.81 150.5,-365.39\"/>\n",
       "<text text-anchor=\"middle\" x=\"160.67\" y=\"-323.34\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.9</text>\n",
       "</g>\n",
       "<!-- &#39;6&#39; -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>&#39;6&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"6.95\" cx=\"333.53\" cy=\"-188.16\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"333.53\" y=\"-184.28\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">suggestion</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;6&#39; -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;6&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M220.98,-241.92C245.15,-230.38 283.08,-212.26 308.12,-200.3\"/>\n",
       "<text text-anchor=\"middle\" x=\"255.93\" y=\"-223.56\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.9</text>\n",
       "</g>\n",
       "<!-- &#39;7&#39; -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>&#39;7&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"6.56\" cx=\"298.36\" cy=\"-25.2\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"298.36\" y=\"-21.32\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">searching</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;7&#39; -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;7&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M208.35,-229.4C227.34,-186.33 267.53,-95.13 287.13,-50.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"239.12\" y=\"-142.48\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2.6</text>\n",
       "</g>\n",
       "<!-- &#39;8&#39; -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>&#39;8&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"4.92\" cx=\"60.34\" cy=\"-213.32\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"60.34\" y=\"-209.45\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">approach</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;8&#39; -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;8&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M173.38,-245.83C148.79,-238.76 111.14,-227.93 86.14,-220.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"121.14\" y=\"-235.74\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.9</text>\n",
       "</g>\n",
       "<!-- &#39;9&#39; -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>&#39;9&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"4.42\" cx=\"25.2\" cy=\"-64.66\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"25.2\" y=\"-60.78\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">log</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;9&#39; -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;9&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M180.79,-234.17C148.01,-198.46 76.88,-120.96 43.37,-84.45\"/>\n",
       "<text text-anchor=\"middle\" x=\"103.45\" y=\"-161.76\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2.7</text>\n",
       "</g>\n",
       "<!-- &#39;10&#39; -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>&#39;10&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"4.18\" cx=\"508.97\" cy=\"-296.21\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"508.97\" y=\"-292.34\" font-family=\"Times New Roman,serif\" font-size=\"10.00\">search</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;10&#39; -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;10&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M223.44,-256.45C281.46,-264.53 423.1,-284.25 482.29,-292.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"344.24\" y=\"-276.92\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3.3</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Graph at 0x2305dd61880>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_graph = ranking.get_graph().get_graph_viz('0.7', 'deepskyblue')\n",
    "visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.33105768434585847)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking.get_graph().get_cosine_similarity(ranking.get_document_by_ranking_position(1).get_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc 1 top 1 sentence similarity: 0.7837700147857163\n",
      "doc 2 top 1 sentence similarity: 0.6197666469316625\n",
      "\n",
      "doc 1 top 2 sentence similarity: 0.6927369875579629\n",
      "doc 2 top 2 sentence similarity: 0.7191345203393451\n",
      "\n",
      "Similarity without include_ponderations\n",
      "doc 1 top 2 sentences: (6, 3)\n",
      "doc 1 similarity: 0.2559578049439363\n",
      "doc 2 top 2 sentences: (7, 7)\n",
      "doc 2 similarity: 0.15146530941850353\n",
      "doc 3 top 2 sentences: (1, 0)\n",
      "doc 3 similarity: 0.253505569044981\n",
      "doc 4 top 2 sentences: (5, 2)\n",
      "doc 4 similarity: 0.23226453802699856\n",
      "doc 5 top 2 sentences: (6, 4)\n",
      "doc 5 similarity: 0.22970096946482377\n",
      "doc 6 top 2 sentences: (2, 4)\n",
      "doc 6 similarity: 0.22317399876638377\n",
      "doc 7 top 2 sentences: (5, 0)\n",
      "doc 7 similarity: 0.21101748718190205\n",
      "doc 8 top 2 sentences: (5, 0)\n",
      "doc 8 similarity: 0.2091860025495047\n",
      "doc 9 top 2 sentences: (1, 0)\n",
      "doc 9 similarity: 0.21513018777787257\n",
      "doc 10 top 2 sentences: (7, 1)\n",
      "doc 10 similarity: 0.21508622677206962\n",
      "\n",
      "Similarity with include_ponderations\n",
      "doc 1 top 2 sentences: (6, 3)\n",
      "doc 1 similarity: 0.28140396119238936\n",
      "doc 2 top 2 sentences: (7, 7)\n",
      "doc 2 similarity: 0.16659685401719845\n",
      "doc 3 top 2 sentences: (1, 0)\n",
      "doc 3 similarity: 0.26771986875316645\n",
      "doc 4 top 2 sentences: (5, 2)\n",
      "doc 4 similarity: 0.24140276683749334\n",
      "doc 5 top 2 sentences: (6, 4)\n",
      "doc 5 similarity: 0.22985536099363243\n",
      "doc 6 top 2 sentences: (2, 0)\n",
      "doc 6 similarity: 0.23157332397617794\n",
      "doc 7 top 2 sentences: (5, 0)\n",
      "doc 7 similarity: 0.20748284119574406\n",
      "doc 8 top 2 sentences: (5, 0)\n",
      "doc 8 similarity: 0.215033443053256\n",
      "doc 9 top 2 sentences: (1, 2)\n",
      "doc 9 similarity: 0.2200533648554025\n",
      "doc 10 top 2 sentences: (7, 1)\n",
      "doc 10 similarity: 0.21614023546007088\n"
     ]
    }
   ],
   "source": [
    "# Top 2 sentence graphs by doc function\n",
    "def get_top2_graph_sentences(doc, include_ponderation=False):\n",
    "    g_user = ranking.get_graph()\n",
    "    top2_graph_sentences = []\n",
    "    for s in doc.get_sentences():\n",
    "        if s.get_graph().get_graph_as_dict():\n",
    "            top2_graph_sentences.append((s.get_position_in_doc(), g_user.get_cosine_similarity(s.get_graph(), include_ponderation)))\n",
    "\n",
    "    if len(top2_graph_sentences) == 1:\n",
    "        return ((top2_graph_sentences[0][0],top2_graph_sentences[0][0]), \n",
    "                (doc.get_sentence_by_position_in_doc(top2_graph_sentences[0][0]).get_graph(),doc.get_sentence_by_position_in_doc(top2_graph_sentences[0][0]).get_graph()))\n",
    "    top2_graph_sentences = sorted(top2_graph_sentences, key=lambda tuple: tuple[1], reverse=True)[:2]\n",
    "    # return -> ((pos_in_doc_1, pos_in_doc_2), (graph1, graph2))\n",
    "    return ((top2_graph_sentences[0][0], top2_graph_sentences[1][0]), \n",
    "            (doc.get_sentence_by_position_in_doc(top2_graph_sentences[0][0]).get_graph(), doc.get_sentence_by_position_in_doc(top2_graph_sentences[1][0]).get_graph()))\n",
    "\n",
    "\n",
    "# Average similarities by document function\n",
    "def avg_sim_doc(g_doc_top2_sentences, include_ponderation=False):\n",
    "    graph_user = ranking.get_graph()\n",
    "    sim_doc_top1 = graph_user.get_cosine_similarity(g_doc_top2_sentences[0], include_ponderation)\n",
    "    sim_doc_top2 = graph_user.get_cosine_similarity(g_doc_top2_sentences[1], include_ponderation)\n",
    "    avg_sim_doc = (sim_doc_top1 + sim_doc_top2) / 2\n",
    "    return avg_sim_doc\n",
    "\n",
    "\n",
    "def print_top2_sentences_by_doc_similarity(include_ponderation: bool = False):\n",
    "    g_docs_top2_sentences = []\n",
    "    avg_sim_docs = []\n",
    "\n",
    "    for index1 in range(nr_search_results):\n",
    "        g_docs_top2_sentences.append(get_top2_graph_sentences(ranking.get_document_by_ranking_position(index1+1), include_ponderation))\n",
    "\n",
    "    for index2 in range(nr_search_results):\n",
    "        avg_sim_docs.append(avg_sim_doc(g_docs_top2_sentences[index2][1], include_ponderation))\n",
    "        \n",
    "    for index3 in range(nr_search_results):\n",
    "        print(f\"doc {index3+1} top 2 sentences: {g_docs_top2_sentences[index3][0]}\")\n",
    "        print(f\"doc {index3+1} similarity: {avg_sim_docs[index3]}\")\n",
    "    \n",
    "\n",
    "\n",
    "tple_doc1 = get_top2_graph_sentences(ranking.get_document_by_ranking_position(1))\n",
    "tple_doc2 = get_top2_graph_sentences(ranking.get_document_by_ranking_position(10))\n",
    "doc1_doc2_sentence_top1_union = tple_doc1[1][0].get_union_to_graph(tple_doc2[1][0])\n",
    "doc1_doc2_sentence_top2_union = tple_doc1[1][1].get_union_to_graph(tple_doc2[1][1])\n",
    "\n",
    "print(f\"doc 1 top 1 sentence similarity: {tple_doc1[1][0].get_cosine_similarity(doc1_doc2_sentence_top1_union)}\")\n",
    "print(f\"doc 10 top 1 sentence similarity: {tple_doc2[1][0].get_cosine_similarity(doc1_doc2_sentence_top1_union)}\")\n",
    "\n",
    "print(f\"\\ndoc 1 top 2 sentence similarity: {tple_doc1[1][1].get_cosine_similarity(doc1_doc2_sentence_top2_union)}\")\n",
    "print(f\"doc 10 top 2 sentence similarity: {tple_doc2[1][1].get_cosine_similarity(doc1_doc2_sentence_top2_union)}\")\n",
    "\n",
    "print(\"\\nSimilarity without include_ponderations\")\n",
    "print_top2_sentences_by_doc_similarity(include_ponderation=False)\n",
    "     \n",
    "print(\"\\nSimilarity with include_ponderations\")\n",
    "print_top2_sentences_by_doc_similarity(include_ponderation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities by document without include_ponderations\n",
      "doc 1: 0.34608009868800965\n",
      "doc 2: 0.15146530941850353\n",
      "doc 3: 0.3543674245752713\n",
      "doc 4: 0.46410602655119304\n",
      "doc 5: 0.36491134534777436\n",
      "doc 6: 0.3341790056040972\n",
      "doc 7: 0.38100335683142084\n",
      "doc 8: 0.25211452715756894\n",
      "doc 9: 0.36344096878273224\n",
      "doc 10: 0.3380229767996377\n",
      "\n",
      "Similarities by document without include_ponderations\n",
      "doc 1: 0.3675566078372686\n",
      "doc 2: 0.16659685401719845\n",
      "doc 3: 0.37356857613444255\n",
      "doc 4: 0.4644933556755862\n",
      "doc 5: 0.36022930335265785\n",
      "doc 6: 0.3463112398779022\n",
      "doc 7: 0.386741403737868\n",
      "doc 8: 0.25934796669511395\n",
      "doc 9: 0.36305069476186685\n",
      "doc 10: 0.33932762453379595\n"
     ]
    }
   ],
   "source": [
    "def print_documents_similatity(include_ponderation: bool = False):\n",
    "    for index, doc in enumerate(ranking.get_documents()):\n",
    "        print(f\"doc {index+1}: {ranking.get_graph().get_cosine_similarity(doc.get_graph(), include_ponderation)}\")\n",
    "\n",
    "print(\"Similarities by document without include_ponderations\")\n",
    "print_documents_similatity(include_ponderation=False)\n",
    "\n",
    "print(\"\\nSimilarities by document without include_ponderations\")\n",
    "print_documents_similatity(include_ponderation=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
