{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from many_stop_words import get_stop_words\n",
    "\n",
    "from nltk.stem import PorterStemmer #Stemmer\n",
    "from textblob import Word #Lemmatize\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "#Define some funtions\n",
    "import srex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize some objects / variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = PorterStemmer()\n",
    "stop_words_list = stopwords.words('english') #a small one\n",
    "newStopWords = get_stop_words('en') # a big one\n",
    "stop_words_list.extend(newStopWords) # all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def text_transformations(parragraph, stopwords=True, lema=True, stem=True):   \n",
    "    \n",
    "    # low the string\n",
    "    parragraph = parragraph.lower()\n",
    "    \n",
    "    # Remove puntuation\n",
    "    tokens = nltk.word_tokenize(parragraph)\n",
    "    filtered_parragraph = [w for w in tokens if w.isalnum()]\n",
    "    \n",
    "    # Remove Stopwords\n",
    "    if(stopwords):\n",
    "        filtered_parragraph = list(filter(lambda word_of_parragraph: (word_of_parragraph not in stop_words_list), filtered_parragraph))\n",
    "    \n",
    "    # Apply lematization\n",
    "    if(lema):\n",
    "        filtered_parragraph = list(map(lambda word_filtered_parragraph: Word(word_filtered_parragraph).lemmatize(), filtered_parragraph))\n",
    "    \n",
    "    # Stemmer\n",
    "    if(stem):\n",
    "        filtered_parragraph = list(map(lambda word: st.stem(word), filtered_parragraph))\n",
    "    \n",
    "    final_string = ' '.join(map(str, filtered_parragraph))\n",
    "    \n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the a dictionary with the document's term positions\n",
    "def get_term_positions_dict(document):\n",
    "    vectorizer = CountVectorizer()\n",
    "    vector = vectorizer.build_tokenizer()(document)\n",
    "    document_positions_dic = defaultdict(list)\n",
    "    for i in range(len(vector)):\n",
    "        document_positions_dic[vector[i]].append(i)\n",
    "    return document_positions_dic\n",
    "\n",
    "document = \"bar bar baz bar guu hee\"\n",
    "doc_term_positions = get_term_positions_dict(document)\n",
    "print(doc_term_positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate a matrix containing the terms positions from a group (list) of cocuments\n",
    "def get_documents_positions_matrix(documents):\n",
    "    term_positions_matrix = []\n",
    "    for doc in documents:\n",
    "        positions_dict = get_term_positions_dict(doc)\n",
    "        term_positions_matrix.append(positions_dict)\n",
    "    return term_positions_matrix\n",
    "\n",
    "document1 = \"foo bar baz\"\n",
    "document2 = \"bar bar baz dee\"\n",
    "document3 = \"bar bar baz dee guu\"\n",
    "document4 = \"bar bar baz bar guu hee\"\n",
    "documents = [document1, document2, document3, document4]\n",
    "term_positions_matrix = get_documents_positions_matrix(documents)\n",
    "print(term_positions_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the positions vectors of two terms, and return the list of distances of the terms that are inside limit_distance\n",
    "def calculate_TermPositions_distances(term_positions1, term_positions2, limit_distance):\n",
    "    neighborhood_positions = [] \n",
    "    for pos1 in term_positions1:\n",
    "        for pos2 in term_positions2:\n",
    "            absolute_distance = abs(pos1-pos2)\n",
    "            if (absolute_distance <= limit_distance):\n",
    "                neighborhood_positions.append(absolute_distance)\n",
    "    return neighborhood_positions\n",
    "print(calculate_TermPositions_distances([1,2,10,20,30], [2,8,22,27,33], 2)) # distances: (1,2)=1 , (10,8)=2 , (20,22)=2 are all <= limit_distance->2\n",
    "print(calculate_TermPositions_distances([1,10,20,30], [2,8,22,27,33], 3)) # distances: same as before plus (30,27)=3 , (30,33)=3  <= limit_distance->3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculates the vecinity of a term in a doument\n",
    "# where:\n",
    "# document_positions_dict : is a dictionary with the positions of all terms in a document\n",
    "# reference_term : is a term used as reference for calculating wich terms are in its vecinity\n",
    "# limit_distance : is the maximal distance of terms used to calculate the vecinity\n",
    "# sumarize : is used to define a function to sumarize the distance of the terms in the vecinity\n",
    "\n",
    "def get_document_term_vecinity_dict(document_positions_dict, reference_term, limit_distance, sumarize='none', include_reference_term=True):\n",
    "    vecinity_dict = {}\n",
    "    # Get the term positions of the reference term\n",
    "    reference_term_positions = document_positions_dict[reference_term]\n",
    "    \n",
    "    # Calculate all terms in document_positions_dict that are at distance limit_distance (or closer) to the reference_term\n",
    "    # and return a list of these terms and their corresponding distances\n",
    "    for term, term_positions in document_positions_dict.items():\n",
    "        # ** HAY QUE REVISAR SI ESTE IF FUNCIONA BIEN\n",
    "        if((term != reference_term) or (include_reference_term)): # Evita que se compare el termino de referencia consigo mismo\n",
    "            # ** AQUI HAY UN PROBLEMA CUANDO reference_term_positions TIENE MAS DE UN ELEMENTO **\n",
    "            neighborhood_positions = calculate_TermPositions_distances(reference_term_positions, term_positions, limit_distance)\n",
    "\n",
    "            if(len(neighborhood_positions)>0):\n",
    "                if (sumarize == 'mean'): vecinity_dict[term] = np.mean(neighborhood_positions)\n",
    "                elif (sumarize == 'median'): vecinity_dict[term] = np.median(neighborhood_positions)\n",
    "                else: vecinity_dict[term] = neighborhood_positions\n",
    "        \n",
    "    return vecinity_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_vecinity_matrix(document_positions_matrix, reference_term, limit_distance, sumarize, include_reference_term):\n",
    "    vecinity_matrix = []\n",
    "    for doc_positions_dic in document_positions_matrix:\n",
    "        document_term_vecinity_dict = get_document_term_vecinity_dict(doc_positions_dic, reference_term, limit_distance, sumarize, include_reference_term)\n",
    "        vecinity_matrix.append(document_term_vecinity_dict)\n",
    "    return vecinity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_collection_vecinity(document_list, reference_term, limit_distance, sumarize_positions, sumarize_vecinity, include_reference_term):\n",
    "    document_positions_matrix = get_documents_positions_matrix(document_list)\n",
    "    vecinity_matrix = get_vecinity_matrix(document_positions_matrix, reference_term, limit_distance, sumarize_positions, include_reference_term)\n",
    "    df = pd.DataFrame.from_dict(vecinity_matrix)\n",
    "    print(df)\n",
    "    df_summarized = df.mean()\n",
    "    df_summarized.sort_values(axis=0, ascending=True, inplace=True, kind='quicksort')\n",
    "    print(df_summarized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "document1 = \"foo bar baz\"\n",
    "document2 = \"bar bar baz dee\"\n",
    "document3 = \"bar bar baz dee guu\"\n",
    "document4 = \"bar bar baz bar guu hee\"\n",
    "documents = [document1, document2, document3, document4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get document positions matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_documents_positions_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-357cfca32361>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdocuments_positions_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_documents_positions_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm_positions_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_documents_positions_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "documents_positions_matrix = get_documents_positions_matrix(documents)\n",
    "print(term_positions_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the vecinity matrix for the term 'bar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecinity_matrix = get_vecinity_matrix(documents_positions_matrix, 'bar', 2, 'mean', True)\n",
    "print(vecinity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcultes the vecinity DataFrame for the term 'bar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame.from_dict(vecinity_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculates the mean distance (graph) of the terms vecinity considering all documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here all documents have the same weight.  \n",
    "For the next version I have to build mean distances considering the document ranking.  \n",
    "That means, the first documents have more weight than de last documents of the ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame.from_dict(vecinity_matrix).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMENTARIOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Como calcular grafos de distancias a partir de los términos en un documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea es calcular una vecindad de los términos de búsqueda, dentro de un documento. Es decir, que términos se encuentran cerca de los términos de busqueda en un documento determinado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texto Ejemplo\n",
    "Supongamos el siguiente documento ejemplo donde calcularemos el grafo asociado al término de búsqueda *'languages'*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"The European languages are members of the same family.\" + \"Their separate existence is a myth. For science, music, sport, etc, Europe uses the same vocabulary. \" + \"The languages only differ in their grammar, their pronunciation and their most common words.\" + \"Everyone realizes why a new common language would be desirable: one could refuse to pay expensive translators.\" + \"To achieve this, it would be necessary to have uniform grammar, pronunciation and more common words.\" + \"If several languages coalesce, the grammar of the resulting language is more simple and regular than that of the individual languages.\" + \"The new common language will be more simple and regular than the existing European languages.\" + \"It will be as simple as Occidental; in fact, it will be Occidental.\" + \"To an English person, it will seem like simplified English, as a skeptical Cambridge friend of mine told me what Occidental is.\" + \"The European languages are members of the same family. \" + \"Their separate existence is a myth. For science, music, sport, etc, Europe uses the same vocabulary. \" + \"The languages only differ in their grammar, their pronunciation and their most common words. \" + \"Everyone realizes why a new common language would be desirable: one could refuse to pay expensive translators.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  **Segmentamos** el documento en un arreglo de párrafos, segun su puntuación.\n",
    "En general existen algunas dificultades para el calculo de los grafos cuando los documentos tienen distintos tamaños. Esto puede ser enfrentado considerando subconjuntos de documentos correspondientes a los parrafos, generados por puntos seguidos y puntos aparte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parragraphs_list = doc.split('.')\n",
    "print(parragraphs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicamos algunas funciones de **depuración de textos** (stop word, stemming, lemma, etc.), utilizando la función **text_transformations()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_parragraphs_list = list(map(lambda x: text_transformations(x, stopwords=True, lema=True, stem=False), parragraphs_list))\n",
    "print(processed_parragraphs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculamos la **matriz de posiciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_pos_matrix = get_documents_positions_matrix(processed_parragraphs_list)\n",
    "print(doc_pos_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matrix de posiciones de documento 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc_pos_matrix[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculamos la **vecindad** para el término _'language'_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecin_matrix = get_vecinity_matrix(doc_pos_matrix, 'language', 5, 'mean', False)\n",
    "print(vecin_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print Vecinity Matrix as DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vecin_matrix = pd.DataFrame.from_dict(vecin_matrix)\n",
    "print(df_vecin_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculates the **mean distance** (graph) of the terms vecinity considering all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame.from_dict(vecin_matrix).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distancia Límite de Cálculo\n",
    "Para calcular la vecindad a un termino de búsqueda definimos una distancia límite de cálculo (*limit_distance*). Por ejemplo, si *limit_distance*=5, el cálculo de la vecindad considerará sólo hasta 5 terminos de distancia desde la posición del término de búsqueda.  \n",
    "Con esto se evita que se realicen *comparaciones cruzadas* entre terminos de búsqueda que se encuentran distribuidos a lo largo del documento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Matrices de Distancias entre Términos\n",
    "\n",
    "* La matriz de vecindad que define la distancia entre un término de referencia (busqueda) y los demás términos del documento fiene las siguientes características\n",
    "  * Los términos no presentes en el documento y que aparaecen en la matriz con el valor *NaN*, pueden ser considerados con distancia _infinita_ al termino de referencia.\n",
    "  * Los termminos de referencia (búsqueda) aparecen en la matriz con distancia *cero*. También se puede modificar el algoritmo para que no aparezcan en la matriz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame.from_dict(vecinity_matrix)) # Esta es la matriz de distancias para el témino 'bar'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Donde aplicar los Grafos\n",
    "\n",
    "Existen varias alternativas donde aplicar los grafos:\n",
    "1. Definir un grafo por el ranking\n",
    "  * Un problema con esta alternativa es como asociar cambios en el grafo a un nuevo ranking\n",
    "2. Definir un grafo por documento\n",
    "3. Definir un grafo por párrafo\n",
    "  * Esto elimina en parte el problema que generan los documentos de tamaño distinto\n",
    "  \n",
    "Probaremos la alternativa (3) de definir un grafo por parrafo, para luego explorar una forma para integrar la información de los grafos que componen el documento en un sólo grafo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ¿Cómo operar sobre Grafos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sumar grafos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para sumar dos grafos asociados a un documento hay que considerar \n",
    "1. Que hacer con los terminos iguales\n",
    "2. Que hacer con los terminos distintos\n",
    "3. etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcular el valor medio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular el valor medio de un grupo de grafos hay que considerar:\n",
    "1. Cada grafo puede tener una ponderación distinta\n",
    "2. Los grafos pueden tener palabras distintas\n",
    "3. etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparar la similitud "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos que definir un indicador de similitud entre grafos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=\"XDBABDCACXC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [i for i, x in enumerate(s) if x == \"A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
