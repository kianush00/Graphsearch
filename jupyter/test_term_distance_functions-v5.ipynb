{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing GraphSearch Distance Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kianu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kianu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kianu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import srex\n",
    "import operator\n",
    "from stop_words import get_stop_words\n",
    "import nltk\n",
    "\n",
    "#Download stopword\n",
    "nltk.download('stopwords') \n",
    "nltk.download('punkt') # Tokenizers\n",
    "nltk.download('wordnet') # Wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize some variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hola este es un *texto*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemmer\n",
    "st = srex.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Words\n",
    "stop_words_list = stopwords.words('english') #a small one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "newStopWords = get_stop_words('en') # a big one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_list.extend(newStopWords) # all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "query                  = 'internet of things'\n",
    "reference_term         = 'iot'\n",
    "nr_search_results      = 10\n",
    "\n",
    "ranking_weight_type    = 'none' # it can be: 'none', 'linear' or 'inverse'\n",
    "limit_distance         = 4 \n",
    "sumarize               = 'none' \n",
    "include_reference_term = False\n",
    "nr_of_graph_terms      = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Articulo de revista científica IEEE Explore\n",
    "#doc = srex.get_ieee_explore_article('article_number', '8316016')\n",
    "\n",
    "# Ranking de documentos de IEEE Explore CON ponderación de documentos\n",
    "results = srex.get_ieee_explore_ranking(query, nr_search_results)\n",
    "\n",
    "# Ranking de documentos de IEEE Explore SIN ponderación de documentos\n",
    "#results = srex.get_ieee_explore_ranking(\"search engine\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " \"can't\",\n",
       " 'cannot',\n",
       " 'could',\n",
       " \"couldn't\",\n",
       " 'did',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " \"he's\",\n",
       " 'her',\n",
       " 'here',\n",
       " \"here's\",\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " \"how's\",\n",
       " 'i',\n",
       " \"i'd\",\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " \"i've\",\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"let's\",\n",
       " 'me',\n",
       " 'more',\n",
       " 'most',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'ought',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 'same',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that's\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " \"there's\",\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 'very',\n",
       " 'was',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we've\",\n",
       " 'were',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " \"what's\",\n",
       " 'when',\n",
       " \"when's\",\n",
       " 'where',\n",
       " \"where's\",\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " \"who's\",\n",
       " 'whom',\n",
       " 'why',\n",
       " \"why's\",\n",
       " 'with',\n",
       " \"won't\",\n",
       " 'would',\n",
       " \"wouldn't\",\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results\n",
    "stop_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_weighted = srex.get_ranking_as_string(results, ranking_weight_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_list = doc_weighted.split('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text transformations\n",
    "\n",
    "Remove stopwords, punctuation, stemming, lematization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_sentences_list = list(map(lambda x: srex.text_transformations(x, stop_words_list, lema=True, stem=False), sentences_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate word positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_pos_matrix = srex.get_documents_positions_matrix(processed_sentences_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate vecinity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecinity_matrix = srex.get_vecinity_matrix(doc_pos_matrix, reference_term, limit_distance, sumarize, include_reference_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_vecinity_dict = srex.get_unique_vecinity_dict(vecinity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_freq_dict = {k: len(v) for k, v in unique_vecinity_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = srex.normalize_dictionary_values(terms_freq_dict, [1,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_terms_freq_dict = sorted(terms_freq_dict.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sorted_terms_freq_dict = {k: v for k, v in list(sorted_terms_freq_dict)[:nr_of_graph_terms]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_distance_dict = {k: {'frequency':terms_freq_dict[k], 'distance':srex.np.median(unique_vecinity_dict[k])} for k in first_sorted_terms_freq_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'network': {'frequency': 20.0, 'distance': 1.0},\n",
       " 'device': {'frequency': 20.0, 'distance': 1.0},\n",
       " 'jammer': {'frequency': 13.666666666666666, 'distance': 2.0},\n",
       " 'reactive': {'frequency': 13.666666666666666, 'distance': 3.0},\n",
       " 'cyber': {'frequency': 13.666666666666666, 'distance': 2.0}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_freq_distance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = srex.getGraphViz(reference_term, most_freq_distance_dict, '0.7', 'deepskyblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 8.0.5 (20230430.1635)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"414pt\" height=\"394pt\"\n",
       " viewBox=\"0.00 0.00 413.74 394.07\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 390.07)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-390.07 409.74,-390.07 409.74,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"#c1cdcd\" stroke=\"black\" cx=\"187.66\" cy=\"-197.44\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"187.66\" y=\"-193.56\" font-family=\"Times,serif\" font-size=\"10.00\">iot</text>\n",
       "</g>\n",
       "<!-- &#39;1&#39; -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>&#39;1&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"20\" cx=\"258.81\" cy=\"-216.01\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"258.81\" y=\"-212.13\" font-family=\"Times,serif\" font-size=\"10.00\">network</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;1&#39; -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;1&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M212.15,-203.83C216.25,-204.9 220.57,-206.03 224.85,-207.15\"/>\n",
       "<text text-anchor=\"middle\" x=\"222.81\" y=\"-192.19\" font-family=\"Times,serif\" font-size=\"14.00\">1.0</text>\n",
       "</g>\n",
       "<!-- &#39;2&#39; -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>&#39;2&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"20\" cx=\"170.08\" cy=\"-125.44\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"170.08\" y=\"-121.56\" font-family=\"Times,serif\" font-size=\"10.00\">device</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;2&#39; -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;2&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M181.61,-172.66C180.58,-168.43 179.49,-163.97 178.41,-159.55\"/>\n",
       "<text text-anchor=\"middle\" x=\"188.63\" y=\"-152.8\" font-family=\"Times,serif\" font-size=\"14.00\">1.0</text>\n",
       "</g>\n",
       "<!-- &#39;3&#39; -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>&#39;3&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"13.67\" cx=\"25.2\" cy=\"-195.9\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"25.2\" y=\"-192.02\" font-family=\"Times,serif\" font-size=\"10.00\">jammer</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;3&#39; -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;3&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M162.28,-197.2C133.81,-196.93 87.6,-196.49 56.81,-196.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"100.92\" y=\"-199.9\" font-family=\"Times,serif\" font-size=\"14.00\">2.0</text>\n",
       "</g>\n",
       "<!-- &#39;4&#39; -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>&#39;4&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"13.67\" cx=\"380.54\" cy=\"-25.2\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"380.54\" y=\"-21.32\" font-family=\"Times,serif\" font-size=\"10.00\">reactive</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;4&#39; -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;4&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M206.51,-180.61C241.96,-148.95 318.48,-80.62 357.15,-46.08\"/>\n",
       "<text text-anchor=\"middle\" x=\"273.2\" y=\"-116.55\" font-family=\"Times,serif\" font-size=\"14.00\">3.0</text>\n",
       "</g>\n",
       "<!-- &#39;5&#39; -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>&#39;5&#39;</title>\n",
       "<ellipse fill=\"none\" stroke=\"deepskyblue\" stroke-width=\"13.67\" cx=\"191.43\" cy=\"-360.87\" rx=\"25.2\" ry=\"25.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"191.43\" y=\"-357\" font-family=\"Times,serif\" font-size=\"10.00\">cyber</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;&#39;5&#39; -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>0&#45;&#45;&#39;5&#39;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M188.25,-222.98C188.91,-251.7 189.99,-298.39 190.7,-329.36\"/>\n",
       "<text text-anchor=\"middle\" x=\"180.85\" y=\"-279.37\" font-family=\"Times,serif\" font-size=\"14.00\">2.0</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Graph at 0x7fb80021a8e0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
